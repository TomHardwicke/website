---
title: "Open data are not enough"
categories: ''
date: '2018-07-30'
draft: yes
slug: open-data-are-not-enough
summary: ''
tags: ''
authors:
- Tom Hardwicke
- Michael Frank
---



<div id="brief-summary" class="section level3">
<h3>Brief summary</h3>
<p><small><em>Access to data can enable a number of important research activities that faciliate verification, discovery, and evidence synthesis, ultimately leading to a more efficient, progressive, and credible scientific ecosystem. Many efforts are underway to increase the amount of data sharing, however it is currently unclear if the in-principle benefits of data sharing are being realized in practice. In a recent study we found that a mandatory data sahring policy introduced at the journal Cognition led to a substantial increase in available data, but we also found that a considerable portion of this data was unlikely to be reusable by other researchers. For data to be reusable, it needs to be clearly structured and well-documented. Open data alone will not be enough to achieve the benefits envisioned by proponents of data sharing.</em></small></p>
<hr />
<p><em>This blog is co-written with Mike Frank.</em></p>
<p>Psychology is currently navigating a period of <a href="https://doi.org/10.1177%2F1745691612465253">crisis</a> and <a href="https://doi.org/10.1177%2F1745691617751884">opportunity</a>. Growing calls for the adoption of <a href="http://doi.org/10.1525/collabra.158">transparent</a> and <a href="https://doi.org/10.1038/s41562-016-0021">reproducible</a> research practices and starting to elicit a response and a number of journals have begin to introduce new policies to implement change. Data availability is an especially pertinant issue because data access can enable a number of important research activities (see Figure <a href="#fig:open-data-activities">1</a>). These include repeating original analyses to recover reported values (analytic reproducibility), employing sensitivity analyses to examine the robustness of outcomes across multiple analysis specifications, conducting novel analyses that make different assumptions or utilise different techniques, and synthesising evidence across multiple studies via meta-analysis. These research activities faciliate verification, discovery, and evidence synthesis and should ultimately lead to a more efficient, progressive, and credible scientific ecosystem.</p>
<p>the extent to which the in-principle benefits of data sharing are being realized in practice is currently unknown.</p>
<p>Our assessment is sure to be an underestimate of data probs - as our more in-depth check revealed a number of data-related problems</p>
<div class="figure"><span id="fig:open-data-activities"></span>
<img src="/img/open-data-activities.png" alt="Open data can enables a number of research activities that faciliate verification, discovery, and evidence synthesis."  />
<p class="caption">
Figure 1: Open data can enables a number of research activities that faciliate verification, discovery, and evidence synthesis.
</p>
</div>
<p>Back in 2015, I (Tom) was visiting the Center for Open Science and joined a project being led by Mallory Kidwell to evaluate the impact of an ‘open badges’ scheme introduced at the journal Psychological Science. The idea was that authors who voluntarily shared their data and/or research materials would have their paper stamped with a colourful badge, signalling their adoption of open practices to the community. This seems to have been pretty successful; introduction of the badges scheme was associated with an almost 10-fold increase in the proportion of articles reporting available data<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. It was great to see so many data sets being shared, but one finding from our paper troubled me: a substantial proportion (50/111, 45%) of reportedly available data was in fact not available, incomplete, incorrect, or had insufficient documentation. This include a few articles that had received open data badges.</p>
<p>ideals of data sharing in principle are not yet being realized in practice</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>see these thought-provoking blogs by Hilda Bastian (<a href="http://blogs.plos.org/absolutely-maybe/2017/08/29/bias-in-open-science-advocacy-the-case-of-article-badges-for-data-sharing/">blog1</a>, <a href="http://blogs.plos.org/absolutely-maybe/2017/09/01/whats-open-whats-data-whats-proof-whats-spin/">blog2</a>) that suggest considerable caution is needed before making causal claims).<a href="#fnref1">↩</a></p></li>
</ol>
</div>
